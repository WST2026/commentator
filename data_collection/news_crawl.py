import requests
from bs4 import BeautifulSoup
import json
import time

def extract_article_text(url):
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")

        # í˜ì´ì§€ ë‚´ ëª¨ë“  <p> íƒœê·¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ì´ì–´ ë¶™ì„
        paragraphs = soup.find_all("p")
        content = "\n".join(
            [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]
        )

        return content if content else "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"
    except Exception as e:
        return f"ì—ëŸ¬: {str(e)}"

def bing_news_search(query, num_articles=100):
    headers = {'User-Agent': 'Mozilla/5.0'}
    articles = []
    offset = 0

    while len(articles) < num_articles:
        url = f"https://www.bing.com/news/search?q={query}&first={offset}"
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")

        results = soup.select("div.news-card")

        if not results:
            print("ğŸ“­ ë” ì´ìƒ ê²°ê³¼ ì—†ìŒ")
            break

        for item in results:
            title_tag = item.select_one("a.title")
            title = title_tag.text.strip() if title_tag else "ì œëª© ì—†ìŒ"
            link = title_tag['href'] if title_tag else "ë§í¬ ì—†ìŒ"
            time_tag = item.select_one("span.source")
            date = time_tag.text.strip() if time_tag else "ë‚ ì§œ ì—†ìŒ"

            print(f"\nâ–¶ [{len(articles)+1}] {title}")
            print(f"URL: {link}")

            content = extract_article_text(link)
            print(f"ë³¸ë¬¸ ê¸¸ì´: {len(content)}ì")

            if not content or "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨" in content or "ì—ëŸ¬:" in content:
                print("âš ï¸ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                continue

            articles.append({
                "title": title,
                "datetime": date,
                "content": content,
                "url": link
            })

            if len(articles) >= num_articles:
                break

            time.sleep(1)

        offset += 10
        time.sleep(1)

    return articles

if __name__ == "__main__":
    result = bing_news_search("ì›”ë“œì»µ 2026", 200)
    with open("bing_articles_full.json", "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ìµœì¢… ì €ì¥ëœ ê¸°ì‚¬ ìˆ˜: {len(result)}ê°œ")
