import os
import sys
import json
import uuid
import yaml
import argparse
from opensearchpy import OpenSearch, helpers

# ê¸°ë³¸ ì„¤ì •
CONFIG_PATH = "../config/upload_config.yaml"
INPUT_JSON = "../data_collection/bing_articles_full.json"
BULK_JSONL = "bulk.jsonl"

# OpenSearch í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
client = OpenSearch("http://localhost:9200")

# ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

index_name = config["index_name"]


# âœ… ì¸ë±ìŠ¤ ì—†ìœ¼ë©´ ìƒì„±
def create_index_if_not_exists(index_name):
    if client.indices.exists(index=index_name):
        print(f"[0] ì¸ë±ìŠ¤ '{index_name}' ì´ë¯¸ ì¡´ì¬")
        return

    mapping = {
        "settings": {
            "index": {
                "number_of_shards": 1,
                "number_of_replicas": 0
            }
        },
        "mappings": {
            "properties": {
                "id": {"type": "keyword"},
                "title": {"type": "text"},
                "content": {"type": "text"},
                "url": {"type": "keyword"},
                "datetime": {"type": "text"},
                "project_name": {"type": "keyword"},
                "file_name": {"type": "keyword"},
                "page": {"type": "integer"}
            }
        }
    }

    client.indices.create(index=index_name, body=mapping)
    print(f"[0] ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì™„ë£Œ")


# âœ… bulk.jsonl íŒŒì¼ ìƒì„±
def convert_json_to_bulk():
    with open(INPUT_JSON, "r", encoding="utf-8") as f:
        data = json.load(f)

    with open(BULK_JSONL, "w", encoding="utf-8") as out:
        for i, item in enumerate(data):
            uid = str(uuid.uuid4())

            meta = {"index": {"_index": index_name, "_id": uid}}
            out.write(json.dumps(meta, ensure_ascii=False) + "\n")

            doc = {
                "title": item.get("title", ""),
                "content": item.get("content", ""),
                "url": item.get("url", ""),
                "datetime": item.get("datetime", ""),
                "project_name": "agentic_rag",
                "file_name": os.path.basename(INPUT_JSON),
                "page": 1,
                "id": uid
            }
            out.write(json.dumps(doc, ensure_ascii=False) + "\n")

    print(f"[1] bulk í¬ë§· ë³€í™˜ ì™„ë£Œ: {BULK_JSONL} ({len(data)}ê°œ ë¬¸ì„œ)")


# âœ… bulk.jsonl â†’ OpenSearch ì—…ë¡œë“œ
def upload_bulk_jsonl():
    with open(BULK_JSONL, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # ì§ìˆ˜ ì¤„: index, document, index, document, ...
    bulk_lines = [json.loads(line) for line in lines]

    # helpers.bulk()ëŠ” (action, document)ì˜ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ìŒ
    actions = []
    for i in range(0, len(bulk_lines), 2):
        meta = bulk_lines[i]["index"]
        doc = bulk_lines[i + 1]
        action = {
            "_op_type": "index",
            "_index": meta["_index"],
            "_id": meta["_id"],
            "_source": doc
        }
        actions.append(action)

    helpers.bulk(client, actions)
    print(f"[2] ì—…ë¡œë“œ ì™„ë£Œ: {len(actions)}ê°œ ë¬¸ì„œ ì—…ë¡œë“œë¨")

    os.remove(BULK_JSONL)
    print(f"[3] ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {BULK_JSONL}")


# âœ… ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸
def check_index():
    print("ğŸ§ª ì¸ë±ìŠ¤ ìƒíƒœ ì ê²€ ì¤‘...")
    if client.indices.exists(index=index_name):
        count = client.count(index=index_name)["count"]
        print(f"âœ… ì¸ë±ìŠ¤ '{index_name}' ì¡´ì¬ (ë¬¸ì„œ ìˆ˜: {count})")
    else:
        print(f"âŒ ì¸ë±ìŠ¤ '{index_name}' ì¡´ì¬í•˜ì§€ ì•ŠìŒ")


# âœ… ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°
def preview_documents(size=5):
    if not client.indices.exists(index=index_name):
        print(f"âŒ ì¸ë±ìŠ¤ '{index_name}' ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        return

    res = client.search(index=index_name, body={"size": size, "query": {"match_all": {}}})
    for i, hit in enumerate(res["hits"]["hits"], 1):
        print(f"\nğŸ“„ Document {i} (ID: {hit['_id']})")
        print(json.dumps(hit["_source"], indent=2, ensure_ascii=False))


# âœ… ëª…ë ¹ì–´ ë¶„ê¸°
if __name__ == "__main__":
    if len(sys.argv) > 1:
        if sys.argv[1] == "check":
            check_index()
        elif sys.argv[1] == "preview":
            preview_documents()
        elif sys.argv[1] == "upload":
            print("ğŸš€ ì—…ë¡œë“œ ì‹œì‘")
            create_index_if_not_exists(index_name)
            convert_json_to_bulk()
            upload_bulk_jsonl()
        else:
            print("â— ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª…ë ¹ì…ë‹ˆë‹¤.")
            print("  python convert_and_upload.py upload    # ë³€í™˜ + ì—…ë¡œë“œ")
            print("  python convert_and_upload.py check     # ì¸ë±ìŠ¤ í™•ì¸")
            print("  python convert_and_upload.py preview   # ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°")
    else:
        print("â— ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (upload | check | preview)")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("command", choices=["upload", "check", "preview"], help="ì‹¤í–‰ ëª…ë ¹")
    parser.add_argument("--field", help="ê²€ìƒ‰í•  í•„ë“œ (id, title, content)")
    parser.add_argument("--value", help="ê²€ìƒ‰ í‚¤ì›Œë“œ")
    parser.add_argument("--size", type=int, default=5, help="ë¯¸ë¦¬ë³´ê¸° ê°œìˆ˜ (ê¸°ë³¸: 5)")

    args = parser.parse_args()

    if args.command == "check":
        check_index()
    elif args.command == "upload":
        print("ğŸš€ ì—…ë¡œë“œ ì‹œì‘")
        create_index_if_not_exists(index_name)
        convert_json_to_bulk()
        upload_bulk_jsonl()
    elif args.command == "preview":
        preview_documents(size=args.size, field=args.field, value=args.value)